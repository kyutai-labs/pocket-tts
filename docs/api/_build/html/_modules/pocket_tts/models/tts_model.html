

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pocket_tts.models.tts_model &mdash; Pocket TTS 1.0.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=9edc463e" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=1ed6394b"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Pocket TTS
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">TTSModel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../audio.html">Audio I/O Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rust_audio.html">Rust Audio Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples.html">Examples</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Pocket TTS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pocket_tts.models.tts_model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pocket_tts.models.tts_model</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">queue</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statistics</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">threading</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">lru_cache</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">safetensors</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Self</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.conditioners.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">TokenizedText</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.data.audio</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_wav</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.data.audio_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">convert_audio</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.default_parameters</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DEFAULT_EOS_THRESHOLD</span><span class="p">,</span>
    <span class="n">DEFAULT_LSD_DECODE_STEPS</span><span class="p">,</span>
    <span class="n">DEFAULT_NOISE_CLAMP</span><span class="p">,</span>
    <span class="n">DEFAULT_TEMPERATURE</span><span class="p">,</span>
    <span class="n">DEFAULT_VARIANT</span><span class="p">,</span>
    <span class="n">MAX_TOKEN_PER_CHUNK</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.models.flow_lm</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlowLMModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.models.mimi</span><span class="w"> </span><span class="kn">import</span> <span class="n">MimiModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">mimi_transformer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.modules.dummy_quantizer</span><span class="w"> </span><span class="kn">import</span> <span class="n">DummyQuantizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.modules.seanet</span><span class="w"> </span><span class="kn">import</span> <span class="n">SEANetDecoder</span><span class="p">,</span> <span class="n">SEANetEncoder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.modules.stateful_module</span><span class="w"> </span><span class="kn">import</span> <span class="n">increment_steps</span><span class="p">,</span> <span class="n">init_states</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.utils.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">Config</span><span class="p">,</span> <span class="n">load_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.utils.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">PREDEFINED_VOICES</span><span class="p">,</span>
    <span class="n">display_execution_time</span><span class="p">,</span>
    <span class="n">download_if_necessary</span><span class="p">,</span>
    <span class="n">load_predefined_voice</span><span class="p">,</span>
    <span class="n">size_of_dict</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pocket_tts.utils.weights_loading</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_flow_lm_state_dict</span><span class="p">,</span> <span class="n">get_mimi_state_dict</span>

<span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="TTSModel">
<a class="viewcode-back" href="../../../models.html#pocket_tts.TTSModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">TTSModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="TTSModel.__init__">
<a class="viewcode-back" href="../../../models.html#pocket_tts.TTSModel.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">flow_lm</span><span class="p">:</span> <span class="n">FlowLMModel</span><span class="p">,</span>
        <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lsd_decode_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">noise_clamp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eos_threshold</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span> <span class="o">=</span> <span class="n">flow_lm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lsd_decode_steps</span> <span class="o">=</span> <span class="n">lsd_decode_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_clamp</span> <span class="o">=</span> <span class="n">noise_clamp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eos_threshold</span> <span class="o">=</span> <span class="n">eos_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_voice_cloning</span> <span class="o">=</span> <span class="kc">True</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">sample_rate</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_from_pydantic_config</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span>
        <span class="n">temp</span><span class="p">,</span>
        <span class="n">lsd_decode_steps</span><span class="p">,</span>
        <span class="n">noise_clamp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eos_threshold</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
        <span class="n">flow_lm</span> <span class="o">=</span> <span class="n">FlowLMModel</span><span class="o">.</span><span class="n">from_pydantic_config</span><span class="p">(</span>
            <span class="n">config</span><span class="o">.</span><span class="n">flow_lm</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">dimension</span>
        <span class="p">)</span>
        <span class="n">tts_model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">flow_lm</span><span class="p">,</span> <span class="n">temp</span><span class="p">,</span> <span class="n">lsd_decode_steps</span><span class="p">,</span> <span class="n">noise_clamp</span><span class="p">,</span> <span class="n">eos_threshold</span><span class="p">,</span> <span class="n">config</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tts_model</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_from_pydantic_config_with_weights</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span>
        <span class="n">temp</span><span class="p">,</span>
        <span class="n">lsd_decode_steps</span><span class="p">,</span>
        <span class="n">noise_clamp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eos_threshold</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
        <span class="n">tts_model</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_from_pydantic_config</span><span class="p">(</span>
            <span class="n">config</span><span class="p">,</span> <span class="n">temp</span><span class="p">,</span> <span class="n">lsd_decode_steps</span><span class="p">,</span> <span class="n">noise_clamp</span><span class="p">,</span> <span class="n">eos_threshold</span>
        <span class="p">)</span>
        <span class="n">tts_model</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">speaker_proj_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">weights_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">weights_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If you specify flow_lm.weights_path you should specify mimi.weights_path&quot;</span>
                <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading FlowLM weights from </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">weights_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">state_dict_flowlm</span> <span class="o">=</span> <span class="n">get_flow_lm_state_dict</span><span class="p">(</span>
                <span class="n">download_if_necessary</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">weights_path</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">tts_model</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict_flowlm</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># safetensors.torch.save_file(tts_model.state_dict(), &quot;7442637a.safetensors&quot;)</span>
        <span class="c1"># Create mimi config directly from the provided config using model_dump</span>
        <span class="n">mimi_config</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()</span>

        <span class="c1"># Build mimi model from config</span>
        <span class="n">encoder</span> <span class="o">=</span> <span class="n">SEANetEncoder</span><span class="p">(</span><span class="o">**</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;seanet&quot;</span><span class="p">])</span>
        <span class="n">decoder</span> <span class="o">=</span> <span class="n">SEANetDecoder</span><span class="p">(</span><span class="o">**</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;seanet&quot;</span><span class="p">])</span>

        <span class="n">encoder_transformer</span> <span class="o">=</span> <span class="n">mimi_transformer</span><span class="o">.</span><span class="n">ProjectedTransformer</span><span class="p">(</span>
            <span class="o">**</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;transformer&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">decoder_transformer</span> <span class="o">=</span> <span class="n">mimi_transformer</span><span class="o">.</span><span class="n">ProjectedTransformer</span><span class="p">(</span>
            <span class="o">**</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;transformer&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">quantizer</span> <span class="o">=</span> <span class="n">DummyQuantizer</span><span class="p">(</span><span class="o">**</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;quantizer&quot;</span><span class="p">])</span>

        <span class="n">tts_model</span><span class="o">.</span><span class="n">mimi</span> <span class="o">=</span> <span class="n">MimiModel</span><span class="p">(</span>
            <span class="n">encoder</span><span class="p">,</span>
            <span class="n">decoder</span><span class="p">,</span>
            <span class="n">quantizer</span><span class="p">,</span>
            <span class="n">channels</span><span class="o">=</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;channels&quot;</span><span class="p">],</span>
            <span class="n">sample_rate</span><span class="o">=</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;sample_rate&quot;</span><span class="p">],</span>
            <span class="n">frame_rate</span><span class="o">=</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;frame_rate&quot;</span><span class="p">],</span>
            <span class="n">encoder_frame_rate</span><span class="o">=</span><span class="n">mimi_config</span><span class="p">[</span><span class="s2">&quot;sample_rate&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">encoder</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span>
            <span class="n">encoder_transformer</span><span class="o">=</span><span class="n">encoder_transformer</span><span class="p">,</span>
            <span class="n">decoder_transformer</span><span class="o">=</span><span class="n">decoder_transformer</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="c1"># Load mimi weights from the config safetensors file with complete mapping for strict loading</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">weights_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">weights_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If you specify mimi.weights_path you should specify flow_lm.weights_path&quot;</span>
                <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading Mimi weights from </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">weights_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">mimi_state</span> <span class="o">=</span> <span class="n">get_mimi_state_dict</span><span class="p">(</span>
                <span class="n">download_if_necessary</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">weights_path</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">tts_model</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">mimi_state</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">tts_model</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># tts_model.to(dtype=torch.float32)</span>

        <span class="c1"># uncomment to save the weights</span>
        <span class="c1"># tts_model = tts_model.to(dtype=torch.bfloat16)</span>
        <span class="c1"># safetensors.torch.save_file(tts_model.state_dict(), &quot;tts_b6369a24.safetensors&quot;)</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">weights_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading TTSModel weights from </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">weights_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">weights_file</span> <span class="o">=</span> <span class="n">download_if_necessary</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">weights_path</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">tts_model</span><span class="o">.</span><span class="n">has_voice_cloning</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">weights_file</span> <span class="o">=</span> <span class="n">download_if_necessary</span><span class="p">(</span>
                    <span class="n">config</span><span class="o">.</span><span class="n">weights_path_without_voice_cloning</span>
                <span class="p">)</span>

            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">safetensors</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">load_file</span><span class="p">(</span><span class="n">weights_file</span><span class="p">)</span>
            <span class="n">tts_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">weights_path</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">weights_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;No weights_path specified for FlowLM or TTSModel, model is uninitialized!&quot;</span>
            <span class="p">)</span>
        <span class="n">size_in_mb</span> <span class="o">=</span> <span class="n">size_of_dict</span><span class="p">(</span><span class="n">tts_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span> <span class="o">//</span> <span class="mf">1e6</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TTS Model loaded successfully. Its size is </span><span class="si">{</span><span class="n">size_in_mb</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tts_model</span>

<div class="viewcode-block" id="TTSModel.load_model">
<a class="viewcode-back" href="../../../models.html#pocket_tts.TTSModel.load_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span>
        <span class="n">variant</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">DEFAULT_VARIANT</span><span class="p">,</span>
        <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_TEMPERATURE</span><span class="p">,</span>
        <span class="n">lsd_decode_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_LSD_DECODE_STEPS</span><span class="p">,</span>
        <span class="n">noise_clamp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">DEFAULT_NOISE_CLAMP</span><span class="p">,</span>
        <span class="n">eos_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">DEFAULT_EOS_THRESHOLD</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a pre-trained TTS model with specified configuration.</span>

<span class="sd">        This class method loads a complete TTS model including the flow language model</span>
<span class="sd">        and Mimi compression model from pre-trained weights. The model is initialized</span>
<span class="sd">        with the specified generation parameters and ready for inference.</span>

<span class="sd">        Args:</span>
<span class="sd">            variant: Model variant identifier corresponding to a config file name</span>
<span class="sd">                (e.g., &#39;610b0b2c&#39;). Must match a YAML file in the config directory.</span>
<span class="sd">            temp: Sampling temperature for generation. Higher values produce more</span>
<span class="sd">                diverse but potentially lower quality output.</span>
<span class="sd">            lsd_decode_steps: Number of steps for Lagrangian Self Distillation</span>
<span class="sd">                decoding. More steps can improve quality but increase computation.</span>
<span class="sd">            noise_clamp: Maximum value for noise sampling. If None, no clamping</span>
<span class="sd">                is applied. Helps prevent extreme values in generation.</span>
<span class="sd">            eos_threshold: Threshold for end-of-sequence detection. Higher values</span>
<span class="sd">                make the model more likely to continue generating.</span>

<span class="sd">        Returns:</span>
<span class="sd">            TTSModel: Fully initialized model with loaded weights on cpu, ready for</span>
<span class="sd">                text-to-speech generation.</span>

<span class="sd">        Raises:</span>
<span class="sd">            FileNotFoundError: If the specified config file or model weights</span>
<span class="sd">                are not found.</span>
<span class="sd">            ValueError: If the configuration is invalid or incompatible.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">load_config</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;config/</span><span class="si">{</span><span class="n">variant</span><span class="si">}</span><span class="s2">.yaml&quot;</span><span class="p">)</span>
        <span class="n">tts_model</span> <span class="o">=</span> <span class="n">TTSModel</span><span class="o">.</span><span class="n">_from_pydantic_config_with_weights</span><span class="p">(</span>
            <span class="n">config</span><span class="p">,</span> <span class="n">temp</span><span class="p">,</span> <span class="n">lsd_decode_steps</span><span class="p">,</span> <span class="n">noise_clamp</span><span class="p">,</span> <span class="n">eos_threshold</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tts_model</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_run_flow_lm_and_increment_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">text_tokens</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">backbone_input_latents</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">audio_conditioning</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;First one is the backbone output, second one is the audio decoding output.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">text_tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">text_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">backbone_input_latents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">backbone_input_latents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">ldim</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">audio_conditioning</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">audio_conditioning</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">dim</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_flow_lm</span><span class="p">(</span>
            <span class="n">text_tokens</span><span class="o">=</span><span class="n">text_tokens</span><span class="p">,</span>
            <span class="n">backbone_input_latents</span><span class="o">=</span><span class="n">backbone_input_latents</span><span class="p">,</span>
            <span class="n">model_state</span><span class="o">=</span><span class="n">model_state</span><span class="p">,</span>
            <span class="n">audio_conditioning</span><span class="o">=</span><span class="n">audio_conditioning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">increment_by</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">text_tokens</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="o">+</span> <span class="n">backbone_input_latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="o">+</span> <span class="n">audio_conditioning</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">increment_steps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="p">,</span> <span class="n">model_state</span><span class="p">,</span> <span class="n">increment</span><span class="o">=</span><span class="n">increment_by</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_run_flow_lm</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">text_tokens</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">backbone_input_latents</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">audio_conditioning</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">text_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">conditioner</span><span class="p">(</span><span class="n">TokenizedText</span><span class="p">(</span><span class="n">text_tokens</span><span class="p">))</span>
        <span class="n">text_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">text_embeddings</span><span class="p">,</span> <span class="n">audio_conditioning</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">output_embeddings</span><span class="p">,</span> <span class="n">is_eos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">_sample_next_latent</span><span class="p">(</span>
            <span class="n">backbone_input_latents</span><span class="p">,</span>
            <span class="n">text_embeddings</span><span class="p">,</span>
            <span class="n">model_state</span><span class="o">=</span><span class="n">model_state</span><span class="p">,</span>
            <span class="n">lsd_decode_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lsd_decode_steps</span><span class="p">,</span>
            <span class="n">temp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temp</span><span class="p">,</span>
            <span class="n">noise_clamp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_clamp</span><span class="p">,</span>
            <span class="n">eos_threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_threshold</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">output_embeddings</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="n">is_eos</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_encode_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">encode_to_latent</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="n">encoded</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">conditioning</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">latents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">speaker_proj_weight</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">conditioning</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_slice_kv_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">num_frames</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Slice KV cache to only keep the first num_frames elements.</span>

<span class="sd">        This optimizes memory usage when caching voice states by discarding</span>
<span class="sd">        unused cache capacity beyond the actual audio prompt length.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_state: The model state dict containing KV caches for all modules</span>
<span class="sd">            num_frames: Number of frames to keep in the KV cache</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">original_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">sliced_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">module_name</span><span class="p">,</span> <span class="n">module_state</span> <span class="ow">in</span> <span class="n">model_state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="s2">&quot;cache&quot;</span> <span class="ow">in</span> <span class="n">module_state</span><span class="p">:</span>
                <span class="c1"># KV cache has shape [2, batch_size, sequence_length, num_heads, dim_per_head]</span>
                <span class="n">cache</span> <span class="o">=</span> <span class="n">module_state</span><span class="p">[</span><span class="s2">&quot;cache&quot;</span><span class="p">]</span>
                <span class="n">original_size</span> <span class="o">+=</span> <span class="n">cache</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">*</span> <span class="n">cache</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span>
                <span class="c1"># Slice to keep only the first num_frames positions</span>
                <span class="n">module_state</span><span class="p">[</span><span class="s2">&quot;cache&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">num_frames</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">sliced_size</span> <span class="o">+=</span> <span class="p">(</span>
                    <span class="n">module_state</span><span class="p">[</span><span class="s2">&quot;cache&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">*</span> <span class="n">module_state</span><span class="p">[</span><span class="s2">&quot;cache&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span>
                <span class="p">)</span>

        <span class="n">memory_saved_mb</span> <span class="o">=</span> <span class="p">(</span><span class="n">original_size</span> <span class="o">-</span> <span class="n">sliced_size</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Sliced KV cache from </span><span class="si">{</span><span class="n">original_size</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> MB to </span><span class="si">{</span><span class="n">sliced_size</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> MB &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;(saved </span><span class="si">{</span><span class="n">memory_saved_mb</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> MB)&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_expand_kv_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Expand KV cache back to full sequence_length for generation.</span>

<span class="sd">        When a model state is retrieved from cache with sliced KV caches,</span>
<span class="sd">        this method expands them back to the full size needed for generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_state: The model state dict containing potentially sliced KV caches</span>
<span class="sd">            sequence_length: Target sequence length to expand caches to</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">module_name</span><span class="p">,</span> <span class="n">module_state</span> <span class="ow">in</span> <span class="n">model_state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="s2">&quot;cache&quot;</span> <span class="ow">in</span> <span class="n">module_state</span><span class="p">:</span>
                <span class="n">cache</span> <span class="o">=</span> <span class="n">module_state</span><span class="p">[</span><span class="s2">&quot;cache&quot;</span><span class="p">]</span>
                <span class="c1"># KV cache has shape [2, batch_size, current_length, num_heads, dim_per_head]</span>
                <span class="n">current_length</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">current_length</span> <span class="o">&lt;</span> <span class="n">sequence_length</span><span class="p">:</span>
                    <span class="c1"># Create expanded cache filled with NaN for unused positions</span>
                    <span class="n">expanded_cache</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                        <span class="p">(</span>
                            <span class="n">cache</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">cache</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                            <span class="n">sequence_length</span><span class="p">,</span>
                            <span class="n">cache</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                            <span class="n">cache</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>
                        <span class="p">),</span>
                        <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;NaN&quot;</span><span class="p">),</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">cache</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">cache</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="c1"># Copy existing data to the beginning</span>
                    <span class="n">expanded_cache</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">current_length</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">cache</span>
                    <span class="n">module_state</span><span class="p">[</span><span class="s2">&quot;cache&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">expanded_cache</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_decode_audio_worker</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">latents_queue</span><span class="p">:</span> <span class="n">queue</span><span class="o">.</span><span class="n">Queue</span><span class="p">,</span> <span class="n">result_queue</span><span class="p">:</span> <span class="n">queue</span><span class="o">.</span><span class="n">Queue</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Worker thread function for decoding audio latents from queue with immediate streaming.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">audio_chunks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">mimi_state</span> <span class="o">=</span> <span class="n">init_states</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mimi</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">latent</span> <span class="o">=</span> <span class="n">latents_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">latent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">mimi_decoding_input</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">latent</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">emb_std</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">emb_mean</span>
                <span class="p">)</span>
                <span class="n">transposed</span> <span class="o">=</span> <span class="n">mimi_decoding_input</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">quantized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">quantizer</span><span class="p">(</span><span class="n">transposed</span><span class="p">)</span>

                <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>
                <span class="n">audio_frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">decode_from_latent</span><span class="p">(</span><span class="n">quantized</span><span class="p">,</span> <span class="n">mimi_state</span><span class="p">)</span>
                <span class="n">increment_steps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mimi</span><span class="p">,</span> <span class="n">mimi_state</span><span class="p">,</span> <span class="n">increment</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
                <span class="n">audio_frame_duration</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">audio_frame</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">sample_rate</span>
                <span class="p">)</span>
                <span class="c1"># We could log the timings here.</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">30</span> <span class="o">+</span> <span class="s2">&quot;Decoded </span><span class="si">%d</span><span class="s2"> ms of audio with mimi in </span><span class="si">%d</span><span class="s2"> ms&quot;</span><span class="p">,</span>
                    <span class="nb">int</span><span class="p">(</span><span class="n">audio_frame_duration</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">),</span>
                    <span class="nb">int</span><span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">audio_chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">audio_frame</span><span class="p">)</span>

                <span class="n">result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="s2">&quot;chunk&quot;</span><span class="p">,</span> <span class="n">audio_frame</span><span class="p">))</span>

                <span class="n">latents_queue</span><span class="o">.</span><span class="n">task_done</span><span class="p">()</span>

            <span class="c1"># Signal completion</span>
            <span class="n">result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="s2">&quot;done&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># Put error in result queue</span>
            <span class="n">result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>

<div class="viewcode-block" id="TTSModel.generate_audio">
<a class="viewcode-back" href="../../../models.html#pocket_tts.TTSModel.generate_audio">[docs]</a>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_audio</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">text_to_generate</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">MAX_TOKEN_PER_CHUNK</span><span class="p">,</span>
        <span class="n">frames_after_eos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">copy_state</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate complete audio tensor from text input.</span>

<span class="sd">        This method generates the full audio output for the given text prompt</span>
<span class="sd">        and returns it as a single tensor. It internally uses the streaming</span>
<span class="sd">        generation method but collects all chunks before returning.</span>

<span class="sd">        This method is NOT thread-safe; separate model instances should be used</span>
<span class="sd">        for concurrent generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_state: Model state dictionary containing hidden states and</span>
<span class="sd">                positional information. Can be obtained from get_state_for_audio_prompt()</span>
<span class="sd">                or init_states(). The state may be modified during generation.</span>
<span class="sd">            text_to_generate: Input text to convert to speech. The text will be</span>
<span class="sd">                automatically formatted (capitalization, punctuation) for optimal</span>
<span class="sd">                generation quality.</span>
<span class="sd">            frames_after_eos: Number of additional frames to generate after</span>
<span class="sd">                detecting end-of-sequence. If None, automatically determined</span>
<span class="sd">                based on text length (1-3 frames).</span>
<span class="sd">            copy_state: Whether to create a deep copy of the model state before</span>
<span class="sd">                generation. If True, preserves the original state for reuse.</span>
<span class="sd">                If False, modifies the input state in-place. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Generated audio tensor with shape [channels, samples]</span>
<span class="sd">                at the model&#39;s sample rate (typically 24kHz). The audio is</span>
<span class="sd">                normalized and ready for playback or saving.</span>
<span class="sd">                You can get the sample rate from the `sample_rate` attribute.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If text_to_generate is empty or invalid.</span>
<span class="sd">            RuntimeError: If generation fails due to model errors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">audio_chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_audio_stream</span><span class="p">(</span>
            <span class="n">model_state</span><span class="o">=</span><span class="n">model_state</span><span class="p">,</span>
            <span class="n">text_to_generate</span><span class="o">=</span><span class="n">text_to_generate</span><span class="p">,</span>
            <span class="n">frames_after_eos</span><span class="o">=</span><span class="n">frames_after_eos</span><span class="p">,</span>
            <span class="n">copy_state</span><span class="o">=</span><span class="n">copy_state</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">audio_chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">audio_chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="TTSModel.generate_audio_stream">
<a class="viewcode-back" href="../../../models.html#pocket_tts.TTSModel.generate_audio_stream">[docs]</a>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_audio_stream</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">text_to_generate</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">MAX_TOKEN_PER_CHUNK</span><span class="p">,</span>
        <span class="n">frames_after_eos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">copy_state</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate audio streaming chunks from text input.</span>

<span class="sd">        This method generates audio from text and yields chunks as they become</span>
<span class="sd">        available, enabling real-time playback or processing. It uses multithreading</span>
<span class="sd">        to parallelize generation and decoding for optimal performance.</span>
<span class="sd">        This method is NOT thread-safe; separate model instances should be used</span>
<span class="sd">        for concurrent generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_state: Model state dictionary containing hidden states and</span>
<span class="sd">                positional information. Can be obtained from get_state_for_audio_prompt()</span>
<span class="sd">                or init_states(). The state may be modified during generation.</span>
<span class="sd">            text_to_generate: Input text to convert to speech. The text will be</span>
<span class="sd">                automatically formatted (capitalization, punctuation) for optimal</span>
<span class="sd">                generation quality.</span>
<span class="sd">            frames_after_eos: Number of additional frames to generate after</span>
<span class="sd">                detecting end-of-sequence. If None, automatically determined</span>
<span class="sd">                based on text length (1-3 frames). Defaults to None.</span>
<span class="sd">            copy_state: Whether to create a deep copy of the model state before</span>
<span class="sd">                generation. If True, preserves the original state for reuse.</span>
<span class="sd">                If False, modifies the input state in-place. Defaults to True.</span>

<span class="sd">        Yields:</span>
<span class="sd">            torch.Tensor: Audio chunks with shape [samples] at the model&#39;s</span>
<span class="sd">                sample rate (typically 24kHz). Chunks are yielded as soon as</span>
<span class="sd">                they are decoded, enabling real-time streaming.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If text_to_generate is empty or invalid.</span>
<span class="sd">            RuntimeError: If generation fails due to model errors or threading issues.</span>

<span class="sd">        Note:</span>
<span class="sd">            This method uses multithreading to parallelize latent generation</span>
<span class="sd">            and audio decoding. Generation performance is logged including</span>
<span class="sd">            real-time factor (RTF) metrics.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># This is a very simplistic way of handling long texts. We could do much better</span>
        <span class="c1"># by using teacher forcing, but it would be a bit slower.</span>
        <span class="c1"># TODO: add the teacher forcing method for long texts where we use the audio of one chunk</span>
        <span class="c1"># as conditioning for the next chunk.</span>
        <span class="n">chunks</span> <span class="o">=</span> <span class="n">split_into_best_sentences</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">conditioner</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">text_to_generate</span><span class="p">,</span> <span class="n">max_tokens</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
            <span class="n">text_to_generate</span><span class="p">,</span> <span class="n">frames_after_eos_guess</span> <span class="o">=</span> <span class="n">prepare_text_prompt</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">frames_after_eos_guess</span> <span class="o">+=</span> <span class="mi">2</span>
            <span class="n">effective_frames</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">frames_after_eos</span>
                <span class="k">if</span> <span class="n">frames_after_eos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">frames_after_eos_guess</span>
            <span class="p">)</span>
            <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_audio_stream_short_text</span><span class="p">(</span>
                <span class="n">model_state</span><span class="o">=</span><span class="n">model_state</span><span class="p">,</span>
                <span class="n">text_to_generate</span><span class="o">=</span><span class="n">chunk</span><span class="p">,</span>
                <span class="n">frames_after_eos</span><span class="o">=</span><span class="n">effective_frames</span><span class="p">,</span>
                <span class="n">copy_state</span><span class="o">=</span><span class="n">copy_state</span><span class="p">,</span>
            <span class="p">)</span></div>


    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_audio_stream_short_text</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">text_to_generate</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">frames_after_eos</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">copy_state</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">copy_state</span><span class="p">:</span>
            <span class="n">model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>

        <span class="c1"># Expand sliced KV caches back to full size for generation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_expand_kv_cache</span><span class="p">(</span><span class="n">model_state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

        <span class="c1"># Set up multithreaded generation and decoding</span>
        <span class="n">latents_queue</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
        <span class="n">result_queue</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>

        <span class="c1"># Start decoder worker thread</span>
        <span class="n">decoder_thread</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span>
            <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_decode_audio_worker</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">latents_queue</span><span class="p">,</span> <span class="n">result_queue</span><span class="p">),</span>
            <span class="n">daemon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;starting timer now!&quot;</span><span class="p">)</span>
        <span class="n">t_generating</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>
        <span class="n">decoder_thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

        <span class="c1"># Generate latents and add them to queue (decoder processes them in parallel)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generate</span><span class="p">(</span>
            <span class="n">model_state</span><span class="o">=</span><span class="n">model_state</span><span class="p">,</span>
            <span class="n">text_to_generate</span><span class="o">=</span><span class="n">text_to_generate</span><span class="p">,</span>
            <span class="n">frames_after_eos</span><span class="o">=</span><span class="n">frames_after_eos</span><span class="p">,</span>
            <span class="n">latents_queue</span><span class="o">=</span><span class="n">latents_queue</span><span class="p">,</span>
            <span class="n">result_queue</span><span class="o">=</span><span class="n">result_queue</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Stream audio chunks as they become available</span>
        <span class="n">total_generated_samples</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;chunk&quot;</span><span class="p">:</span>
                <span class="c1"># Audio chunk available immediately for streaming/playback</span>
                <span class="n">audio_chunk</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">total_generated_samples</span> <span class="o">+=</span> <span class="n">audio_chunk</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">yield</span> <span class="n">audio_chunk</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># Remove batch, channel</span>
            <span class="k">elif</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;done&quot;</span><span class="p">:</span>
                <span class="c1"># Generation complete</span>
                <span class="k">break</span>
            <span class="k">elif</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;error&quot;</span><span class="p">:</span>
                <span class="c1"># Wait for decoder thread to finish cleanly before propagating error</span>
                <span class="k">with</span> <span class="n">display_execution_time</span><span class="p">(</span><span class="s2">&quot;Waiting for mimi decoder to finish&quot;</span><span class="p">):</span>
                    <span class="n">decoder_thread</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
                <span class="c1"># Propagate error</span>
                <span class="k">raise</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Wait for decoder thread to finish cleanly</span>
        <span class="k">with</span> <span class="n">display_execution_time</span><span class="p">(</span><span class="s2">&quot;Waiting for mimi decoder to finish&quot;</span><span class="p">):</span>
            <span class="n">decoder_thread</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

        <span class="c1"># Print timing information</span>
        <span class="n">duration_generated_audio</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
            <span class="n">total_generated_samples</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">sample_rate</span>
        <span class="p">)</span>
        <span class="n">generation_time</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_generating</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">real_time_factor</span> <span class="o">=</span> <span class="n">duration_generated_audio</span> <span class="o">/</span> <span class="n">generation_time</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Generated: </span><span class="si">%d</span><span class="s2"> ms of audio in </span><span class="si">%d</span><span class="s2"> ms so </span><span class="si">%.2f</span><span class="s2">x faster than real-time&quot;</span><span class="p">,</span>
            <span class="n">duration_generated_audio</span><span class="p">,</span>
            <span class="n">generation_time</span><span class="p">,</span>
            <span class="n">real_time_factor</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_generate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">text_to_generate</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">frames_after_eos</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">latents_queue</span><span class="p">:</span> <span class="n">queue</span><span class="o">.</span><span class="n">Queue</span><span class="p">,</span>
        <span class="n">result_queue</span><span class="p">:</span> <span class="n">queue</span><span class="o">.</span><span class="n">Queue</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">gen_len_sec</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_to_generate</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">+</span> <span class="mf">2.0</span>
        <span class="n">max_gen_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">gen_len_sec</span> <span class="o">*</span> <span class="mf">12.5</span><span class="p">)</span>
        <span class="n">prepared</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">conditioner</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">text_to_generate</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">display_execution_time</span><span class="p">(</span><span class="s2">&quot;Prompting text&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_run_flow_lm_and_increment_step</span><span class="p">(</span>
                <span class="n">model_state</span><span class="o">=</span><span class="n">model_state</span><span class="p">,</span> <span class="n">text_tokens</span><span class="o">=</span><span class="n">prepared</span><span class="o">.</span><span class="n">tokens</span>
            <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">run_generation</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_autoregressive_generation</span><span class="p">(</span>
                    <span class="n">model_state</span><span class="p">,</span> <span class="n">max_gen_len</span><span class="p">,</span> <span class="n">frames_after_eos</span><span class="p">,</span> <span class="n">latents_queue</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error in autoregressive generation: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="c1"># Signal decoder to stop by putting None (completion sentinel)</span>
                <span class="k">if</span> <span class="n">latents_queue</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">latents_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="c1"># Report error to main thread</span>
                <span class="k">if</span> <span class="n">result_queue</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>

        <span class="n">generation_thread</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">run_generation</span><span class="p">,</span> <span class="n">daemon</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">generation_thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_autoregressive_generation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">max_gen_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">frames_after_eos</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">latents_queue</span><span class="p">:</span> <span class="n">queue</span><span class="o">.</span><span class="n">Queue</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">backbone_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">ldim</span><span class="p">),</span>
            <span class="n">fill_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;NaN&quot;</span><span class="p">),</span>
            <span class="n">device</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">steps_times</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">eos_step</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">generation_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_gen_len</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">display_execution_time</span><span class="p">(</span>
                <span class="s2">&quot;Generating latent&quot;</span><span class="p">,</span> <span class="n">print_output</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">timer</span><span class="p">:</span>
                <span class="n">next_latent</span><span class="p">,</span> <span class="n">is_eos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_flow_lm_and_increment_step</span><span class="p">(</span>
                    <span class="n">model_state</span><span class="o">=</span><span class="n">model_state</span><span class="p">,</span> <span class="n">backbone_input_latents</span><span class="o">=</span><span class="n">backbone_input</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">is_eos</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="ow">and</span> <span class="n">eos_step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">eos_step</span> <span class="o">=</span> <span class="n">generation_step</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">eos_step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">generation_step</span> <span class="o">&gt;=</span> <span class="n">eos_step</span> <span class="o">+</span> <span class="n">frames_after_eos</span>
                <span class="p">):</span>
                    <span class="k">break</span>

                <span class="c1"># Add generated latent to queue for immediate decoding</span>
                <span class="n">latents_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">next_latent</span><span class="p">)</span>
                <span class="n">backbone_input</span> <span class="o">=</span> <span class="n">next_latent</span>
            <span class="n">steps_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">timer</span><span class="o">.</span><span class="n">elapsed_time_ms</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;KPOCKET_TTS_ERROR_WITHOUT_EOS&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;1&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Generation reached maximum length without EOS!&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Maximum generation length reached without EOS, this very often indicates an error.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Add sentinel value to signal end of generation</span>
        <span class="n">latents_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Average generation step time: </span><span class="si">%d</span><span class="s2"> ms&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">statistics</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">steps_times</span><span class="p">))</span>
        <span class="p">)</span>

    <span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_cached_get_state_for_audio_prompt</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">audio_conditioning</span><span class="p">:</span> <span class="n">Path</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">truncate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_state_for_audio_prompt</span><span class="p">(</span><span class="n">audio_conditioning</span><span class="p">,</span> <span class="n">truncate</span><span class="p">)</span>

<div class="viewcode-block" id="TTSModel.get_state_for_audio_prompt">
<a class="viewcode-back" href="../../../models.html#pocket_tts.TTSModel.get_state_for_audio_prompt">[docs]</a>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_state_for_audio_prompt</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">audio_conditioning</span><span class="p">:</span> <span class="n">Path</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">truncate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create model state conditioned on audio prompt for continuation.</span>

<span class="sd">        This method processes an audio prompt and creates a model state that</span>
<span class="sd">        captures the acoustic characteristics (speaker voice, style, prosody)</span>
<span class="sd">        for use in subsequent text-to-speech generation. The resulting state</span>
<span class="sd">        enables voice cloning and audio continuation with speaker consistency.</span>

<span class="sd">        Args:</span>
<span class="sd">            audio_conditioning: Audio prompt to condition on. Can be:</span>
<span class="sd">                - Path: Local file path to audio file</span>
<span class="sd">                - str: URL to download audio file from</span>
<span class="sd">                - torch.Tensor: Pre-loaded audio tensor with shape [channels, samples]</span>
<span class="sd">            truncate: Whether to truncate long audio prompts to 30 seconds.</span>
<span class="sd">                Helps prevent memory issues with very long inputs. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: Model state dictionary containing hidden states and positional</span>
<span class="sd">                information conditioned on the audio prompt. This state can be</span>
<span class="sd">                passed to `generate_audio()` or `generate_audio_stream()` for</span>
<span class="sd">                voice-consistent generation.</span>

<span class="sd">        Raises:</span>
<span class="sd">            FileNotFoundError: If audio file path doesn&#39;t exist.</span>
<span class="sd">            ValueError: If audio tensor is invalid or empty.</span>
<span class="sd">            RuntimeError: If audio processing or encoding fails.</span>

<span class="sd">        Note:</span>
<span class="sd">            - Audio is automatically resampled to the model&#39;s sample rate (24kHz)</span>
<span class="sd">            - The audio is encoded using the Mimi compression model and projected</span>
<span class="sd">              to the flow model&#39;s latent space</span>
<span class="sd">            - Processing time is logged for performance monitoring</span>
<span class="sd">            - The state preserves speaker characteristics for voice cloning</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">audio_conditioning</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">audio_conditioning</span> <span class="ow">in</span> <span class="n">PREDEFINED_VOICES</span>
        <span class="p">):</span>
            <span class="c1"># We get the audio conditioning directly from the safetensors file.</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="n">load_predefined_voice</span><span class="p">(</span><span class="n">audio_conditioning</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_voice_cloning</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">audio_conditioning</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;We could not download the weights for the model with voice cloning, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but you&#39;re trying to use voice cloning. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Without voice cloning, you can use our catalog of voices </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">PREDEFINED_VOICES</span><span class="p">)</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;If you want access to the model with voice cloning, go to &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;https://huggingface.co/kyutai/pocket-tts and accept the terms, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;then make sure you&#39;re logged in locally with `uvx hf auth login`.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">audio_conditioning</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">audio_conditioning</span> <span class="o">=</span> <span class="n">download_if_necessary</span><span class="p">(</span><span class="n">audio_conditioning</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">audio_conditioning</span><span class="p">,</span> <span class="n">Path</span><span class="p">):</span>
                <span class="n">audio</span><span class="p">,</span> <span class="n">conditioning_sample_rate</span> <span class="o">=</span> <span class="n">load_wav</span><span class="p">(</span><span class="n">audio_conditioning</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">truncate</span><span class="p">:</span>
                    <span class="n">max_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                        <span class="mi">30</span> <span class="o">*</span> <span class="n">conditioning_sample_rate</span>
                    <span class="p">)</span>  <span class="c1"># 30 seconds of audio</span>
                    <span class="k">if</span> <span class="n">audio</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">max_samples</span><span class="p">:</span>
                        <span class="n">audio</span> <span class="o">=</span> <span class="n">audio</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">max_samples</span><span class="p">]</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Audio truncated to first 30 seconds (</span><span class="si">{</span><span class="n">max_samples</span><span class="si">}</span><span class="s2"> samples)&quot;</span>
                        <span class="p">)</span>

                <span class="n">audio_conditioning</span> <span class="o">=</span> <span class="n">convert_audio</span><span class="p">(</span>
                    <span class="n">audio</span><span class="p">,</span> <span class="n">conditioning_sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="mi">1</span>
                <span class="p">)</span>

            <span class="k">with</span> <span class="n">display_execution_time</span><span class="p">(</span><span class="s2">&quot;Encoding audio prompt&quot;</span><span class="p">):</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_audio</span><span class="p">(</span>
                    <span class="n">audio_conditioning</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># import safetensors.torch</span>
                <span class="c1"># safetensors.torch.save_file(</span>
                <span class="c1">#     {&quot;audio_prompt&quot;: prompt},</span>
                <span class="c1">#     &quot;/projects/huggingface/pocket-tts/embeddings/cosette.safetensors&quot;</span>
                <span class="c1"># )</span>

        <span class="n">model_state</span> <span class="o">=</span> <span class="n">init_states</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_lm</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">display_execution_time</span><span class="p">(</span><span class="s2">&quot;Prompting audio&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_run_flow_lm_and_increment_step</span><span class="p">(</span>
                <span class="n">model_state</span><span class="o">=</span><span class="n">model_state</span><span class="p">,</span> <span class="n">audio_conditioning</span><span class="o">=</span><span class="n">prompt</span>
            <span class="p">)</span>

        <span class="c1"># Optimize memory by slicing KV cache to only keep frames from the audio prompt</span>
        <span class="n">num_audio_frames</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_slice_kv_cache</span><span class="p">(</span><span class="n">model_state</span><span class="p">,</span> <span class="n">num_audio_frames</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">model_state</span></div>
</div>



<span class="k">def</span><span class="w"> </span><span class="nf">prepare_text_prompt</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">text</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Text prompt cannot be empty&quot;</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;  &quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="n">number_of_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">number_of_words</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">frames_after_eos_guess</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">frames_after_eos_guess</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Make sure it starts with an uppercase letter</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">isupper</span><span class="p">():</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">+</span> <span class="n">text</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

    <span class="c1"># Let&#39;s make sure it ends with some kind of punctuation</span>
    <span class="c1"># If it ends with a letter or digit, we add a period.</span>
    <span class="k">if</span> <span class="n">text</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">isalnum</span><span class="p">():</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span>

    <span class="c1"># The model does not perform well when there are very few tokens, so</span>
    <span class="c1"># we can add empty spaces at the beginning to increase the token count.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">+</span> <span class="n">text</span>

    <span class="k">return</span> <span class="n">text</span><span class="p">,</span> <span class="n">frames_after_eos_guess</span>


<span class="k">def</span><span class="w"> </span><span class="nf">split_into_best_sentences</span><span class="p">(</span>
    <span class="n">tokenizer</span><span class="p">,</span> <span class="n">text_to_generate</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">text_to_generate</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_text_prompt</span><span class="p">(</span><span class="n">text_to_generate</span><span class="p">)</span>
    <span class="n">text_to_generate</span> <span class="o">=</span> <span class="n">text_to_generate</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text_to_generate</span><span class="p">)</span>
    <span class="n">list_of_tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">end_of_sentence_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;.!...?&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="n">end_of_sentences_indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">previous_was_end_of_sentence_token</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">for</span> <span class="n">token_idx</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">list_of_tokens</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">end_of_sentence_tokens</span><span class="p">:</span>
            <span class="n">previous_was_end_of_sentence_token</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">previous_was_end_of_sentence_token</span><span class="p">:</span>
                <span class="n">end_of_sentences_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_idx</span><span class="p">)</span>
            <span class="n">previous_was_end_of_sentence_token</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">end_of_sentences_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">list_of_tokens</span><span class="p">))</span>

    <span class="n">nb_tokens_and_sentences</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">end_of_sentences_indices</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># let&#39;s print</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">end_of_sentences_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">end_of_sentences_indices</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sp</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">list_of_tokens</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
        <span class="n">nb_tokens_and_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>

    <span class="n">max_nb_tokens_in_a_chunk</span> <span class="o">=</span> <span class="n">max_tokens</span>
    <span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_chunk</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">current_nb_of_tokens_in_chunk</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">nb_tokens</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">nb_tokens_and_sentences</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">current_chunk</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">current_chunk</span> <span class="o">=</span> <span class="n">sentence</span>
            <span class="n">current_nb_of_tokens_in_chunk</span> <span class="o">=</span> <span class="n">nb_tokens</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="n">current_nb_of_tokens_in_chunk</span> <span class="o">+</span> <span class="n">nb_tokens</span> <span class="o">&gt;</span> <span class="n">max_nb_tokens_in_a_chunk</span><span class="p">:</span>
            <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_chunk</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
            <span class="n">current_chunk</span> <span class="o">=</span> <span class="n">sentence</span>
            <span class="n">current_nb_of_tokens_in_chunk</span> <span class="o">=</span> <span class="n">nb_tokens</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">current_chunk</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">sentence</span>
            <span class="n">current_nb_of_tokens_in_chunk</span> <span class="o">+=</span> <span class="n">nb_tokens</span>

    <span class="k">if</span> <span class="n">current_chunk</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
        <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_chunk</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">chunks</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Kyutai.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>