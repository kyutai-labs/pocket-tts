{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"export_voice/","title":"Export Voice Command Documentation","text":"<p>Kyutai Pocket TTS allows you to generate speech from an audio sample. However, processing an audio file each time is relatively slow and inefficient.</p> <p>The <code>export-voice</code> command allows you to convert an audio file to a voice embedding in safetensors format. The safetensors file can then be loaded very quickly whenever you generate speech.</p>"},{"location":"export_voice/#basic-usage","title":"Basic Usage","text":"<pre><code>uvx pocket-tts export-voice audio-path export-path\n# or if installed manually:\npocket-tts export-voice audio-path export-path\n</code></pre>"},{"location":"export_voice/#command-options","title":"Command Options","text":""},{"location":"export_voice/#required-parameters","title":"Required Parameters","text":"<ul> <li><code>audio-path</code>: Path of the audio file or directory to convert. <code>audio-path</code> can point to an <code>http:</code> or <code>hf:</code> (hugging face) file. If <code>audio-path</code> is a local directory, all audio files found inside it will be batch converted. Supports popular audio file formats like wav and mp3.</li> <li><code>export-path</code>: Path of safetensors file or directory to export to. For batch conversion, export-path should be a directory. The directory will be created if it does not exist.</li> </ul>"},{"location":"export_voice/#options","title":"Options","text":"<ul> <li><code>--truncate</code>: Automatically truncate long audio files down to 30 seconds.</li> </ul> <p>The other parameters such as <code>--lsd-decode-steps</code> and <code>--temperature</code> are the same as for the <code>generate</code> command. See the generate documentation for more details.</p>"},{"location":"export_voice/#examples","title":"Examples","text":"<pre><code># export a single file\npocket-tts export-voice voice_memo127762.mp3 jack.safetensors\n\n# export a single file to a different directory (output is embbeddings/mary.safetensors\npocket-tts export-voice voices/mary.wav embeddings/\n\n# export an entire directory of audio files, truncate long audios\npocket-tts export-voice voices/ embeddings/ --truncate\n\n# export an online file to current directory\npocket-tts export-voice https://huggingface.co/kyutai/tts-voices/resolve/main/alba-mackenna/announcer.wav .\n\n# use the exported safetensors\npocket-tts generate --text \"Hello, welcome to today's game between the Bears and Cubs.\"  --voice announcer.safetensors\n</code></pre> <p>Note: to indicate a directory rather than a file, please be sure to include a trailing / (\\ on Windows).</p>"},{"location":"generate/","title":"Generate Command Documentation","text":"<p>The <code>generate</code> command allows you to generate speech from text directly from the command line using Kyutai Pocket TTS.</p>"},{"location":"generate/#basic-usage","title":"Basic Usage","text":"<pre><code>uvx pocket-tts generate\n# or if installed manually:\npocket-tts generate\n</code></pre> <p>This will generate a WAV file <code>./tts_output.wav</code> with the default text and voice.</p>"},{"location":"generate/#command-options","title":"Command Options","text":""},{"location":"generate/#core-options","title":"Core Options","text":"<ul> <li><code>--text TEXT</code>: Text to generate (default: \"Hello world! I am Kyutai Pocket TTS. I'm fast enough to run on small CPUs. I hope you'll like me.\")</li> <li><code>--voice VOICE</code>: Path to audio conditioning file (voice to clone) (default: \"hf://kyutai/tts-voices/alba-mackenna/casual.wav\"). Urls and local paths are supported.</li> <li><code>--output-path OUTPUT_PATH</code>: Output path for generated audio (default: \"./tts_output.wav\")</li> </ul>"},{"location":"generate/#generation-parameters","title":"Generation Parameters","text":"<ul> <li><code>--config CONFIG_PATH</code>: Path to custom config.yaml (for loading local model files) or model signature (default: \"b6369a24\")</li> <li><code>--lsd-decode-steps LSD_DECODE_STEPS</code>: Number of generation steps (default: 1)</li> <li><code>--temperature TEMPERATURE</code>: Temperature for generation (default: 0.7)</li> <li><code>--noise-clamp NOISE_CLAMP</code>: Noise clamp value (default: None)</li> <li><code>--eos-threshold EOS_THRESHOLD</code>: EOS threshold (default: -4.0)</li> <li><code>--frames-after-eos FRAMES_AFTER_EOS</code>: Number of frames to generate after EOS (default: None, auto-calculated based on the text length). Each frame is 80ms.</li> </ul>"},{"location":"generate/#performance-options","title":"Performance Options","text":"<ul> <li><code>--device DEVICE</code>: Device to use (default: \"cpu\", you may not get a speedup by using a gpu since it's a small model)</li> <li><code>--quiet</code>, <code>-q</code>: Disable logging output</li> </ul>"},{"location":"generate/#examples","title":"Examples","text":""},{"location":"generate/#basic-generation","title":"Basic Generation","text":"<pre><code># Generate with default settings\npocket-tts generate\n\n# Custom text\npocket-tts generate --text \"Hello, this is a custom message.\"\n\n# Custom output path\npocket-tts generate --output-path \"./my_audio.wav\"\n</code></pre>"},{"location":"generate/#voice-selection","title":"Voice Selection","text":"<pre><code># Use different voice from HuggingFace\npocket-tts generate --voice \"hf://kyutai/tts-voices/jessica-jian/casual.wav\"\n\n# Use local voice file\npocket-tts generate --voice \"./my_voice.wav\"\n\n# Use a safetensors file (such as one created using `pocket-tts export-voice`)\npocket-tts generate --voice \"./my_voice.safetensors\"\n</code></pre>"},{"location":"generate/#quality-tuning","title":"Quality Tuning","text":"<pre><code># Higher quality (more steps)\npocket-tts generate --lsd-decode-steps 5 --temperature 0.5\n\n# More expressive (higher temperature)\npocket-tts generate --temperature 1.0\n\n# Adjust EOS threshold, smaller means finishing earlier.\npocket-tts generate --eos-threshold -3.0\n</code></pre>"},{"location":"generate/#custom-model-config","title":"Custom Model Config","text":"<p>If you'd like to override the paths from which the models are loaded, you can provide a custom YAML configuration. </p> <p>Copy pocket_tts/config/b6369a24.yaml and change weights_path:, weights_path_without_voice_cloning: and tokenizer_path: to the paths of the models you want to load. </p> <p>Then, use the --config option to point to your newly created config.</p> <pre><code># Use a different config\npocket-tts generate --config \"C://pocket-tts/my_config.yaml\"\n</code></pre>"},{"location":"generate/#output-format","title":"Output Format","text":"<p>The generate command always outputs WAV files in the following format: - Sample Rate: 24kHz - Channels: Mono - Bit Depth: 16-bit PCM - Format: Standard WAV file</p> <p>For more advanced usage, see the Python API documentation or consider using the serve command for web-based generation and quick iteration.</p>"},{"location":"python-api/","title":"Python API Documentation","text":"<p>Kyutai Pocket TTS provides a Python API for integrating text-to-speech capabilities into your applications.</p>"},{"location":"python-api/#installation","title":"Installation","text":"<pre><code>pip install pocket-tts\n</code></pre>"},{"location":"python-api/#quick-start","title":"Quick Start","text":"<pre><code>from pocket_tts import TTSModel\nimport scipy.io.wavfile\n\n# Load the model\ntts_model = TTSModel.load_model()\n\n# Get voice state from an audio file\nvoice_state = tts_model.get_state_for_audio_prompt(\n    \"hf://kyutai/tts-voices/alba-mackenna/casual.wav\"\n)\n\n# Generate audio\naudio = tts_model.generate_audio(voice_state, \"Hello world, this is a test.\")\n\n# Save to file\nscipy.io.wavfile.write(\"output.wav\", tts_model.sample_rate, audio.numpy())\n</code></pre>"},{"location":"python-api/#core-classes","title":"Core Classes","text":""},{"location":"python-api/#ttsmodel","title":"TTSModel","text":"<p>The main class for text-to-speech generation.</p>"},{"location":"python-api/#class-methods","title":"Class Methods","text":""},{"location":"python-api/#load_modelconfigb6369a24-temp07-lsd_decode_steps1-noise_clampnone-eos_threshold-40","title":"<code>load_model(config=\"b6369a24\", temp=0.7, lsd_decode_steps=1, noise_clamp=None, eos_threshold=-4.0)</code>","text":"<p>Load and return a TTSModel instance with pre-trained weights.</p> <p>Parameters: - <code>config</code> (str): Path to model config YAML file or a variant identifier (default: \"b6369a24\") - <code>temp</code> (float): Sampling temperature for generation (default: 0.7) - <code>lsd_decode_steps</code> (int): Number of generation steps (default: 1) - <code>noise_clamp</code> (float | None): Maximum value for noise sampling (default: None) - <code>eos_threshold</code> (float): Threshold for end-of-sequence detection (default: -4.0)</p> <p>Returns: - <code>TTSModel</code>: Loaded model instance on CPU</p> <p>Example: <pre><code>from pocket_tts import TTSModel\n\n# Load with default settings\nmodel = TTSModel.load_model()\n\n# Load with custom parameters\nmodel = TTSModel.load_model(variant=\"b6369a24\", temp=0.5, lsd_decode_steps=5, eos_threshold=-3.0)\n</code></pre></p>"},{"location":"python-api/#properties","title":"Properties","text":""},{"location":"python-api/#device-str","title":"<code>device</code> (str)","text":"<p>Returns the device type where the model is running (\"cpu\" or \"cuda\"). By default, the model runs on CPU.</p> <pre><code>from pocket_tts import TTSModel\n\nmodel = TTSModel.load_model()\nprint(f\"Model running on: {model.device}\")\n</code></pre>"},{"location":"python-api/#sample_rate-int","title":"<code>sample_rate</code> (int)","text":"<p>Returns the generated audio sample rate (typically 24000 Hz).</p> <pre><code>from pocket_tts import TTSModel\n\nmodel = TTSModel.load_model()\nprint(f\"Sample rate: {model.sample_rate} Hz\")\n</code></pre>"},{"location":"python-api/#methods","title":"Methods","text":""},{"location":"python-api/#get_state_for_audio_promptaudio_conditioning-truncatefalse","title":"<code>get_state_for_audio_prompt(audio_conditioning, truncate=False)</code>","text":"<p>Extract model state for a given audio file or URL (voice cloning), or load from a .safetensors file.</p> <p>Parameters: - <code>audio_conditioning</code> (Path | str | torch.Tensor): Audio or .safetensors file path, URL, or tensor - <code>truncate</code> (bool): Whether to truncate the audio (default: False)</p> <p>Returns: - <code>dict</code>: Model state dictionary containing hidden states and positional information</p> <p>Example: <pre><code>from pocket_tts import TTSModel\n\nmodel = TTSModel.load_model()\n# From HuggingFace URL\nvoice_state = model.get_state_for_audio_prompt(\"hf://kyutai/tts-voices/alba-mackenna/casual.wav\")\n\n# From local file\nvoice_state = model.get_state_for_audio_prompt(\"./my_voice.wav\")\n\n# Reload state from a .safetensors file (much faster than extracting from an audio file)\nvoice_state = model.get_state_for_audio_prompt(\"./my_voices.safetensors\")\n\n# From HTTP URL\nvoice_state = model.get_state_for_audio_prompt(\n    \"https://huggingface.co/kyutai/tts-voices/resolve\"\n    \"/main/expresso/ex01-ex02_default_001_channel1_168s.wav\"\n)\n</code></pre></p>"},{"location":"python-api/#generate_audiomodel_state-text_to_generate-frames_after_eosnone-copy_statetrue","title":"<code>generate_audio(model_state, text_to_generate, frames_after_eos=None, copy_state=True)</code>","text":"<p>Generate complete audio tensor from text input.</p> <p>Parameters: - <code>model_state</code> (dict): Model state from <code>get_state_for_audio_prompt()</code> - <code>text_to_generate</code> (str): Text to convert to speech - <code>frames_after_eos</code> (int | None): Frames to generate after EOS detection (default: None) - <code>copy_state</code> (bool): Whether to copy the state (default: True)</p> <p>Returns: - <code>torch.Tensor</code>: Audio 1D tensor with shape [samples]</p> <p>Example: <pre><code>from pocket_tts import TTSModel\n\nmodel = TTSModel.load_model()\n\nvoice_state = model.get_state_for_audio_prompt(\"hf://kyutai/tts-voices/alba-mackenna/casual.wav\")\n\n# Generate audio\naudio = model.generate_audio(voice_state, \"Hello world!\", frames_after_eos=2, copy_state=True)\n\nprint(f\"Generated audio shape: {audio.shape}\")\nprint(f\"Audio duration: {audio.shape[-1] / model.sample_rate:.2f} seconds\")\n</code></pre></p>"},{"location":"python-api/#generate_audio_streammodel_state-text_to_generate-frames_after_eosnone-copy_statetrue","title":"<code>generate_audio_stream(model_state, text_to_generate, frames_after_eos=None, copy_state=True)</code>","text":"<p>Generate audio streaming chunks from text input.</p> <p>Parameters: Same as <code>generate_audio()</code></p> <p>Yields: - <code>torch.Tensor</code>: Audio chunks with shape [samples]</p> <p>Example: <pre><code>from pocket_tts import TTSModel\n\nmodel = TTSModel.load_model()\n\nvoice_state = model.get_state_for_audio_prompt(\"hf://kyutai/tts-voices/alba-mackenna/casual.wav\")\n# Stream generation\nfor chunk in model.generate_audio_stream(voice_state, \"Long text content...\"):\n    # Process each chunk as it's generated\n    print(f\"Generated chunk: {chunk.shape[0]} samples\")\n    # Could save chunks to file or play in real-time\n</code></pre></p>"},{"location":"python-api/#save_audio_promptaudio_conditioning-export_path-truncatefalse","title":"<code>save_audio_prompt(audio_conditioning, export_path, truncate=False)</code>","text":"<p>Save audio prompt to a .safetensors file.</p> <p>Parameters: - <code>audio_conditioning</code> (Path | str | torch.Tensor): Audio file path, URL, or tensor - <code>export_path</code> (Path | str): .safetensors file path - <code>truncate</code> (bool): Whether to truncate the audio (default: False)</p> <p>Returns: - tensor of the converted audio.</p> <p>Example: <pre><code>from pocket_tts import TTSModel\n\nmodel = TTSModel.load_model()\n# From HuggingFace URL\nmodel.get_state_for_audio_prompt(\n    \"hf://kyutai/tts-voices/alba-mackenna/casual.wav\", \"casual.safetensors\"\n)\n\n# From local file (the .safetensors extension will be added automatically)\ntensor = model.get_state_for_audio_prompt(\"./my_voice.wav\", \"my_voice\")\n\n# Use the tensor, Luke!\naudio = model.generate_audio(tensor, \"Hello world!\")\n</code></pre></p>"},{"location":"python-api/#advanced-usage","title":"Advanced Usage","text":""},{"location":"python-api/#voice-management","title":"Voice Management","text":"<pre><code>from pocket_tts import TTSModel\n\nmodel = TTSModel.load_model()\n# Preload multiple voices\nvoices = {\n    \"casual\": model.get_state_for_audio_prompt(\"hf://kyutai/tts-voices/alba-mackenna/casual.wav\"),\n    \"funny\": model.get_state_for_audio_prompt(\n        \"https://huggingface.co/kyutai/tts-voices/resolve/main/expresso/ex01-ex02_default_001_channel1_168s.wav\"\n    ),\n}\n\n# Generate with different voices\ncasual_audio = model.generate_audio(voices[\"casual\"], \"Hey there!\")\nfunny_audio = model.generate_audio(voices[\"funny\"], \"Good morning.\")\n</code></pre>"},{"location":"python-api/#batch-processing","title":"Batch Processing","text":"<pre><code>from pocket_tts import TTSModel\nimport scipy.io.wavfile\nimport torch\n\nmodel = TTSModel.load_model()\n\nvoice_state = model.get_state_for_audio_prompt(\"hf://kyutai/tts-voices/alba-mackenna/casual.wav\")\n# Process multiple texts efficiently by re-using the same voice state\ntexts = [\n    \"First sentence to generate.\",\n    \"Second sentence to generate.\",\n    \"Third sentence to generate.\",\n]\n\naudios = []\nfor text in texts:\n    audio = model.generate_audio(voice_state, text)\n    audios.append(audio)\n\n# Concatenate all audio\nfull_audio = torch.cat(audios, dim=0)\nscipy.io.wavfile.write(\"batch_output.wav\", model.sample_rate, full_audio.numpy())\n</code></pre>"},{"location":"python-api/#streaming-to-file","title":"Streaming to File","text":"<p>You can refer to our CLI implementation which can stream audio to a wav file.</p> <p>For more information about the command-line interface, see the Generate Documentation or Serve Documentation.</p>"},{"location":"serve/","title":"Serve Command Documentation","text":"<p>The <code>serve</code> command starts a FastAPI web server that provides both a web interface and HTTP API for text-to-speech generation.</p>"},{"location":"serve/#basic-usage","title":"Basic Usage","text":"<pre><code>uvx pocket-tts serve\n# or if installed manually:\npocket-tts serve\n</code></pre> <p>This starts a server on <code>http://localhost:8000</code> with the default voice model.</p>"},{"location":"serve/#command-options","title":"Command Options","text":"<ul> <li><code>--voice VOICE</code>: Path to voice prompt audio file (voice to clone) (default: \"hf://kyutai/tts-voices/alba-mackenna/casual.wav\")</li> <li><code>--host HOST</code>: Host to bind to (default: \"localhost\")</li> <li><code>--port PORT</code>: Port to bind to (default: 8000)</li> <li><code>--reload</code>: Enable auto-reload for development</li> <li><code>--config</code>: Path to a custom config .yaml</li> </ul>"},{"location":"serve/#examples","title":"Examples","text":""},{"location":"serve/#basic-server","title":"Basic Server","text":"<pre><code># Start with default settings\npocket-tts serve\n\n# Custom host and port\npocket-tts serve --host \"localhost\" --port 8080\n</code></pre>"},{"location":"serve/#custom-voice","title":"Custom Voice","text":"<pre><code># Use different voice\npocket-tts serve --voice \"hf://kyutai/tts-voices/jessica-jian/casual.wav\"\n\n# Use local voice file\npocket-tts serve --voice \"./my_voice.wav\"\n</code></pre>"},{"location":"serve/#custom-model-config","title":"Custom Model Config","text":"<p>If you'd like to override the paths from which the models are loaded, you can provide a custom YAML configuration. </p> <p>Copy pocket_tts/config/b6369a24.yaml and change weights_path:, weights_path_without_voice_cloning: and tokenizer_path: to the paths of the models you want to load. </p> <p>Then, use the --config option to point to your newly created config.</p> <pre><code># Use a different config\npocket-tts serve --config \"C://pocket-tts/my_config.yaml\"\n</code></pre>"},{"location":"serve/#web-interface","title":"Web Interface","text":"<p>Once the server is running, navigate to <code>http://localhost:8000</code> to access the web interface.</p> <p>For more advanced usage, see the Python API documentation for direct integration with the TTS model.</p>"}]}